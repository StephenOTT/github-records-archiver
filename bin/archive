#!/usr/bin/env ruby
# Backs up a GitHub organization's repositories and
# all their associated information for archival purposes.
# Usage: ruby archive.rb

# stdlib
require 'yaml'
require 'logger'
require 'fileutils'
require 'open3'
require 'optparse'

# gems
require 'octokit'
require 'dotenv'

# variable to hold
parse_options = {}

optparse = OptionParser.new do |opts|
  opts.on('-o', '--org ORGANIZATION', "Organization Name") do |f|
    parse_options[:org] = f
  end
  opts.on("-v" "--version issues,wiki,repo", Array, "Version Issues, Wiki and/or Repo") do |list|
     parse_options[:version] = list
  end
end

optparse.parse!

# Configuration
Dotenv.load
Octokit.auto_paginate = true
token    = ENV["GITHUB_TOKEN"]
org      = parse_options[:org] || ENV["GITHUB_ORGANIZATION"]
dest_dir = ENV["GITHUB_ARCHIVE_DIR"] || File.expand_path("./archive/#{org}")

client   = Octokit::Client.new :access_token => token
logger   = Logger.new(STDOUT)
pwd      = Dir.pwd
start    = Time.now

# Timestamp each archive of the organization while still allowing custom archive directory in ENV
if parse_options.has_key?(:version) == true and parse_options[:version].include?("repo")
  dest_dir = "#{dest_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
end

# properties to extract from each issue for the archive
issue_keys = [:title, :number, :state, :html_url, :created_at, :closed_at]
milestone_keys = [:title, :number, :description, :state]

# Run a git command, piping output to stdout
def git(*args)
  system "git " + args.join(" ")
end

# Init the archive dir
logger.info "Starting archive for #{org} in #{dest_dir}"
FileUtils.mkdir_p dest_dir unless Dir.exists? dest_dir

# Fetch all organization repositories
repos = client.organization_repositories org
logger.info "Found #{repos.count} repos"

# Loop through each repository
repos.each do |repo|
  repo_dir = File.expand_path repo.name, dest_dir
  clone_url = "https://#{token}:x-oauth-basic@github.com/#{org}/#{repo.name}.git"
  logger.info "  Archiving #{repo.name} to #{repo_dir}"

  # Git content
  if Dir.exists? repo_dir # Repo already exists, just pull new objects
    logger.info "    #{repo_dir} already exists. Pulling down updates"
    Dir.chdir repo_dir
    git "pull"
  else # Clone Git content from scratch
    logger.info "    #{repo_dir} does not exist. Cloning."
    git "clone", clone_url, repo_dir
  end

  # Clone wiki content
  if repo.has_wiki?
    wiki_clone_url = "https://#{token}:x-oauth-basic@github.com/#{org}/#{repo.name}.wiki.git"
    wiki_dir = File.expand_path "wiki", repo_dir

    if parse_options.has_key?(:version) == true and parse_options[:version].include?("wiki")
      wiki_dir = "#{wiki_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
    end

    logger.info "    Archiving #{repo.name}'s Wiki to #{wiki_dir}"
    `git clone #{wiki_clone_url} #{wiki_dir}`
  end

  # Create an issues directory
  issues_dir = File.expand_path "issues", repo_dir

  if parse_options.has_key?(:version) == true and parse_options[:version].include?("issues")
    issues_dir = "#{issues_dir}/#{start.strftime('%Y%m%dT%H%M%S')}"
  end

  FileUtils.mkdir_p(issues_dir) unless Dir.exists? issues_dir

  # Pull down issues and pull requests
  issues = client.list_issues repo.full_name, :state => "all"
  logger.info "    Found #{issues.count} issues for #{repo.name}"

  # Loop through each issue or pull request
  issues.each do |issue|
    issue_path = File.expand_path "#{issue.number}.md", issues_dir
    logger.info "      Archiving issue ##{issue.number} to #{issue_path}"

    # Pull out issue meta (title, number, created date, etc.)
    meta = {}
    issue_keys.each { |key| meta[key.to_s] = issue[key] }
    meta["user"] = issue.user.login
    meta["tags"] = issue.labels.map {|l| l.name}
    meta["milestone"] = issue.milestone.to_h.select {|k,v| milestone_keys.include?(k) }.map{ |k, v| {k.to_s => v}}
    meta["assignee"] = issue.assignee.login

    # Begin to format our output
    output = meta.to_yaml
    output << "---\n\n"
    output << "# #{issue.title}\n\n"
    output << issue.body

    # Pull down and add comments
    if issue.comments > 0
      comments = client.issue_comments repo.full_name, issue.number
      logger.info "        Found #{comments.count} comments for issue ##{issue.number}"

      # Loop through each comment
      comments.each do |comment|
        output << "\n\n---\n"
        output << "@#{comment.user.login} at #{comment.created_at} wrote:\n\n"
        output << comment.body
      end
    end

    # Write issue + comments to disk
    File.write issue_path, output
  end
end

Dir.chdir pwd
logger.info "Done in #{Time.now - start} seconds."
